{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5470a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnet_preprocess_input\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.utils import class_weight\n",
    "from google.colab import drive\n",
    "\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "ZIP_PATH = '/content/drive/MyDrive/processed_dataset.zip'\n",
    "EXTRACT_TO = '/content/dataset'\n",
    "IMG_SIZE = (380, 380)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_PHASE1 = 15\n",
    "EPOCHS_PHASE2 = 65\n",
    "LEARNING_RATE_PHASE1 = 0.0001\n",
    "LEARNING_RATE_PHASE2 = 0.00001\n",
    "\n",
    "if not os.path.exists(EXTRACT_TO):\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_TO)\n",
    "\n",
    "base_dir = EXTRACT_TO\n",
    "if 'processed_dataset' in os.listdir(base_dir):\n",
    "    base_dir = os.path.join(base_dir, 'processed_dataset')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=resnet_preprocess_input,\n",
    "    rotation_range=40, horizontal_flip=True, zoom_range=0.3, shear_range=0.3,\n",
    "    brightness_range=[0.5, 1.5], fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=resnet_preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'\n",
    ")\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'\n",
    ")\n",
    "\n",
    "y_train = train_generator.classes\n",
    "class_weights_array = class_weight.compute_class_weight(\n",
    "    class_weight='balanced', classes=np.unique(y_train), y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights_array))\n",
    "\n",
    "df_index = 3; mel_index = 4; bcc_index = 1; bkl_index = 2; vasc_index = 6; akiec_index = 0\n",
    "\n",
    "\n",
    "class_weights[bkl_index] = class_weights[bkl_index] * 0.30\n",
    "class_weights[df_index] = class_weights[df_index] * 0.75\n",
    "\n",
    "\n",
    "critical_indices = [mel_index, bcc_index, akiec_index, vasc_index]\n",
    "for index in critical_indices:\n",
    "    class_weights[index] = class_weights[index] * 2.00\n",
    "\n",
    "\n",
    "\n",
    "print(\"ResNet50V2 is downloading...\")\n",
    "\n",
    "base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d35b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.000001)\n",
    "]\n",
    "\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE_PHASE1),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"\\n--- STEP 1: Custom Head Training ({EPOCHS_PHASE1} Tur) ---\")\n",
    "history_phase1 = model.fit(\n",
    "    train_generator, epochs=EPOCHS_PHASE1, validation_data=validation_generator,\n",
    "    class_weight=class_weights, callbacks=[callbacks[1]]\n",
    ")\n",
    "\n",
    "\n",
    "base_model.trainable = True\n",
    "fine_tune_at = int(len(base_model.layers) * 0.70)\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE_PHASE2),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"\\n--- STEP 2: Fine-Tuning ({EPOCHS_PHASE2} Tur) ---\")\n",
    "history_phase2 = model.fit(\n",
    "    train_generator, epochs=EPOCHS_PHASE1 + EPOCHS_PHASE2,\n",
    "    initial_epoch=history_phase1.epoch[-1] + 1, validation_data=validation_generator,\n",
    "    class_weight=class_weights, callbacks=callbacks\n",
    ")\n",
    "\n",
    "\n",
    "model.save_weights('final_resnet_oversampled_weights.weights.h5')\n",
    "with open('class_indices.json', 'w') as f:\n",
    "    json.dump(train_generator.class_indices, f)\n",
    "print(\"\\n COMPLETED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "\n",
    "fine_tune_at = int(len(base_model.layers) * 0.70)\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "LEARNING_RATE_PHASE2 = 0.00001\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE_PHASE2),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"Model is ready for fine tuning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de98e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_PHASE1 = 15\n",
    "EPOCHS_PHASE2 = 65\n",
    "total_epochs = EPOCHS_PHASE1 + EPOCHS_PHASE2 \n",
    "initial_epoch_start = 5 + 1 \n",
    "\n",
    "print(f\"\\n--- STEP 2: Fine-Tuning ({EPOCHS_PHASE2} Tur) ---\")\n",
    "print(f\"Eğitim Epoch {initial_epoch_start}'dan itibaren devam ediyor (Toplam {total_epochs} tura kadar).\")\n",
    "\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=initial_epoch_start, \n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "\n",
    "model.save_weights('final_resnet_oversampled_weights.weights.h5')\n",
    "print(\"\\nFine tuning is completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f0d2663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ağırlık yüklenirken hata oluştu: `by_name` only supports loading legacy '.h5' or '.hdf5' files. Received: C:/Users/USER/Desktop/projects/skin-ai-app/backend/final_resnet_oversampled_weights.weights.h5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense # Diğer katmanlar da olabilir\n",
    "\n",
    "# 1. Model Mimarisi: (Bu sadece bir varsayımdır. Kendi ResNet mimarinizi kullanmalısınız!)\n",
    "# Bu örnek, bir ResNet50'nin üstüne eklenmiş basit bir sınıflandırma başlığıdır.\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "# Kaç sınıfınız olduğunu buraya yazın (Örnek: 7 sınıf)\n",
    "num_classes = 7\n",
    "\n",
    "# ResNet50'yi yüklüyoruz (hazır ağırlıklar olmadan)\n",
    "base_model = ResNet50(weights=None, include_top=False, input_shape=(380, 380, 3)) \n",
    "# 'boyut' yerine kendi görüntü boyutunuzu (örn: 224) yazın.\n",
    "\n",
    "# Modelin üstüne kendi sınıflandırma başlığınızı ekleyin (Önemli!)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # Çıkış katmanı\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# 2. Ağırlıkları Yükleme\n",
    "weights_path = \"C:/Users/USER/Desktop/projects/skin-ai-app/backend/final_resnet_oversampled_weights.weights.h5\"\n",
    "try:\n",
    "    # `by_name=True` kullanmak, katman adları eşleştiği sürece daha güvenlidir.\n",
    "    model.load_weights(weights_path, by_name=True) \n",
    "    print(\"Ağırlıklar başarıyla yüklendi.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ağırlık yüklenirken hata oluştu: {e}\")\n",
    "    # Eğer bu adımda hata alırsanız, mimariniz (model) kaydedilen ağırlıklarla eşleşmiyor demektir.\n",
    "    \n",
    "# Modeli tahmin yapmaya hazır hale getirmek için derlemeye gerek yok, ancak \n",
    "# değerlendirme yapmak isterseniz gereklidir.\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f37eb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2003 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Test verilerinizin bulunduğu ana dizinin yolu\n",
    "test_data_dir = \"C:/Users/USER/Desktop/projects/skin-model/processed_dataset/test\" # Lütfen bu yolu kendi test klasörünüzün yoluyla değiştirin.\n",
    "img_height, img_width = 380, 380 # Model mimarinizle aynı olmalı\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # Sadece yeniden ölçekleme (rescale)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=1, # Tek tek tahmin yapmak en iyisidir\n",
    "    class_mode='categorical',\n",
    "    shuffle=False # SIRALAMANIN KORUNMASI İÇİN ÇOK ÖNEMLİ!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7475df1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Tahminleri yap\n",
    "Y_pred = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size + 1)\n",
    "\n",
    "# Gerçek (true) ve Tahmin Edilen (predicted) etiketleri al\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Sınıf İsimleri (Modelin sınıf indeksleriyle eşleşmeli)\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Confusion Matrix'i hesapla\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Confusion Matrix'i görselleştir\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Gerçek Etiket (True Label)')\n",
    "plt.xlabel('Tahmin Edilen Etiket (Predicted Label)')\n",
    "plt.show() # \n",
    "\n",
    "# Ek olarak: Sınıflandırma Raporu (Precision, Recall, F1-Score)\n",
    "print(\"Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
